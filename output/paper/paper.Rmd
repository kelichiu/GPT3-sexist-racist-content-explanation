---
output: 
  bookdown::pdf_document2:
    citation_package: natbib
    keep_tex: false
    toc: false
    fig_caption: true
    latex_engine: xelatex
    template: templates/svm-latex-ms.tex
bibliography: "references.bib"
header-includes:
  -  \usepackage{hyperref}
  -  \usepackage{amsmath}
biblio-style: apalike
title: "Explaining Sexism or Racism with GPT-3 (temp)"
thanks: "Code and data are available at: https://github.com/kelichiu/GPT3-sexist-racist-content-explanation. We gratefully acknowledge the support of Gillian Hadfield and the Schwartz Reisman Institute for Technology and Society. We thank Amy Farrow, Haoluan Chen, Mauricio Vargas Sepúlveda, and Tom Davidson for helpful suggestions. Comments on the `r format(Sys.time(), '%d %B %Y')` version of this paper are welcome at: rohan.alexander@utoronto.ca."
author:
- name: Ke-Li Chiu
  affiliation: University of Toronto
- name: Rohan Alexander
  affiliation: University of Toronto and Schwartz Reisman Institute
abstract: "abstract..."
keywords: "GPT-3; natural language processing; quantitative analysis; hate speech."
date: "`r format(Sys.time(), '%B %d, %Y')`"
geometry: margin=1in
fontfamily: mathpazo
fontsize: 12pt
endnote: no
graphics: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=80), echo = FALSE, warning = FALSE)
library(dplyr)
library(tidyverse)
library(tidyr)
library(readr)
```

# Introduction

To read and digest: Trust is a primary reason for acceptance. Trust is crucial in all kinds of relationships, such as human-social interactions, seller-buyer relationships, and relationships among members of a virtual team. Trust can also define the way people interact with technology [@siau2018building].

To read and digest: This is often how trust appears to work: it involves a (more or less elaborate) explanation of the person or thing that we may or may not trust. Such explanations  we  may  simply  accept,  or  we  may  base  our decisions  upon  them.  If  you  have  given  me  satisfactory explanations in the past, I may even refrain from requesting them in the future [@pieters2011explanation].

**Stress on that this is not Explainable AI. Why it's not Explainable AI? What overlapped with Explainable AI?**

# Background

## Previous paper

## Sharon et al. paper

## GPT-3

GPT-3 is groundbreaking for a few reasons. First of all, GPT-3 are not specialized in one or just a few tasks; it can generally do anything you want it to do. Second, it learns like human do; you just show it a few examples, and it will pick up the patterns in your example, and produce the results you want. Third, the examples and instructions you feed to the model are expressed in natural language. In other words, you are programming with plain language without writing any code. Finally, the model generates the text very quickly and very fluently, and the text contents are hard to be distinguished from human creation. We will see more examples now.


# Methods

1 annotator

## Dataset: Ethos Hate Speech Dataset
Two formats: open-ended and structured. 

Because GPT-3’s responses can be very different each time, we prompt GPT-3 five times for each example to help us examine the variety of the responses and also increase the chance of getting a reasonable response.

Structured: We come up with a set of attributes such as targets, the presence of violence, derogatory, and profanity. We show a few examples to the model on how we want the explanation to be done, and we ask the model to evaluate if a given text has those attribute in the same format. 

Eight attributes: target, targeting type, derogatory, profanity, obscenity, violence, rejection, and accusation. 
Offensive language 

Violence: inciting violence towards the target. Mentioning violence from other event does not count. 
Rejection: explicit expression of not wanting the presence or existence of a target. 
Accusation: accusing the target of misconducts of mischievous behaviours.  

Unclear target or targeting type is not included.
Supremacy is not included.

## Open-Ended Prompts

Prompt:

> Q: Is the following text in quotes sexist? Answer yes or no and explain why.
>
> '''If men shouldnt hit women because we are physically stronnger... then women shouldnt talk because they are fucking louder.'''
>
> A: 

GPT-3 response: 

> Yes this is sexist. This statement is using the stereotypical gender roles of men and women to justify why it is ok for men to hit women but it is not ok for women to speak. Men are seen as physically stronger and women are seen as the loud, screeching sex. This is a perfect example of the sexism in our society.

## Structured Prompts

### Eight Attributes

> '''What about a global massacre of men? Pussiezzz only girls'''
>
> [target: men | targeting type: gender| violence: yes | insult: yes | rejection: no | accusation: no]
>
> '''kill all the african american monkeys'''
>
> [target: african american | targeting type: race| violence: yes | insult: yes | rejection: no | accusation: no]
>
> '''Women are made for making babies and cooking dinner and nothing else!!!'''
>
> [target: women | targeting type: gender| violence: no | insult: yes | rejection: no | accusation: no]
>
> '''The world would be better without white people because they stole from the black Egyptians in the before christ ages they was poor we wasnt whites  ruins everything for black people/White people have pig dicks and no shape no hips or no booty they have to get plastic surgery as us blacks get it from our mother whites brought skin cancer to america so learn some facts before you try to run us out america when we was here before yall racist ass smelly crackers and dont say you will beat my ass because you cant and if you wanna find out drop your adress‚'''
>
> [target: white | targeting type: race| violence: yes | insult: yes| rejection: yes | accusation: yes]
>
> '''You should know women's sports are a joke'''
>
> [

GPT-3 response: 

> target: women's sports | targeting type: gender| violence: no | derogatory: yes | profanity: no | obscenities: no | rejection: no | accusation: no

# Results

## Open-Ended Responses

### Binary results

Before the generation of an explanation, GPT-3 is asked to identify first if a given text is sexist or racist by answering "yes" or "no". The following table shows matches and mismatches of such identification. If GPT-3 answers "yes", or in any other way to indicate a text is sexist or racist, the answer is a match, regardless the adequacy of the explanation. The number of samples are the aggregated counts of the five explanation of each comment. The results shown in Table X indicate that the majority of times GPT-3 did not successfully identify sexist or racist text contents. 

```{r binaryresultagg}
open_ended_results_raw <- read.csv(here::here("output/data/open_ended_results_with_human_label.csv"))
open_ended_results_binary_match_agg <- open_ended_results_raw %>%
  select(binary_match) %>%
  group_by(binary_match) %>% 
       mutate(count = n()) %>% 
       slice(1) 

open_ended_results_binary_match_agg <- open_ended_results_binary_match_agg %>% 
  mutate(binary_match = factor(binary_match)) %>% 
  mutate("Binary Match" = ifelse(binary_match == 1, "Match", "Mistmatch"))
open_ended_results_binary_match_agg <- open_ended_results_binary_match_agg[ , c("Binary Match", "count")] 
colnames(open_ended_results_binary_match_agg) <- c("Binary Match", "Count")
open_ended_results_binary_match_agg %>% 
  knitr::kable(caption = "Open-ended result aggregated binary match count",
               booktabs = TRUE)
```

In each set of the five generated outputs to one given text, we count the number of times where GPT-3 successfully identify the given text as sexist or racist. If in three or more out of the five times the model has successful identification with one given example, it is marked as `majority correct`. The results of such the `majority correct` count is displayed in Table X. In 38 out of the 77 cases, the model has been right more frequently than wrong in identifying sexist or racist text. 

```{r binaryresult}
open_ended_results_binary_match <- open_ended_results_raw %>% 
  select(binary_match, comment) %>% 
  group_by(comment, binary_match) %>% 
       mutate(count = n()) %>% 
       slice(1) %>% 
       mutate(majority_correct = case_when(
                                binary_match == 0 & count > 2 ~ 0, 
                                binary_match == 0 & count < 3 ~ 1,
                                binary_match == 1 & count > 2 ~ 1, 
                                binary_match == 1 & count < 3 ~ 0)
              ) %>% 
       subset(select = -c(binary_match, count))%>% 
       unique()%>% 
       subset(select = -c(comment))%>% 
       group_by(majority_correct)%>% 
       mutate(count = n()) %>% 
       slice(1) 


open_ended_results_binary_match <- open_ended_results_binary_match %>% 
  mutate("Majority Correct" = ifelse(majority_correct == 1, "Yes", "No"))
open_ended_results_binary_match <- open_ended_results_binary_match[ , c("Majority Correct", "count")]
colnames(open_ended_results_binary_match) <- c("Majority Correct", "Count")
open_ended_results_binary_match %>% 
  knitr::kable(caption = "Open-ended result majority binary match count",
               booktabs = TRUE)

```

### Reasoning Adequacy

For the 179 generations where GPT-3 successfully identify the sexist or racist text, we further examine the adequacy of the generated explanations. Table X showcases the count of the adequacy labels of the 179 evaluations. In 76 out of 179 times, the model's explanations are constructed with false reasoning. In 59 cases, the model generated explanations with complete reasoning; in 5 cases, the model generated explanation with completed reasoning accompanied with overreaching reasoning. In 25 cases, the model produced explanations with insufficient reasoning; in 14 cases the model did not produce any explanation or the produced contents are not aimed to provide any explanation. 

```{r reasoningAdequacy}
open_ended_results_reason <- open_ended_results_raw %>%
  filter(binary_match == 1) %>%
  group_by(reasoning) %>%
  mutate(count = n()) %>% 
  slice(1) %>% 
  select(reasoning, count)

colnames(open_ended_results_reason) <- c("Reasoning Adequacy", "Count")
open_ended_results_reason %>% 
  arrange(desc(Count)) %>% 
  knitr::kable(caption = "Open-ended result reasoning level counts",
               booktabs = TRUE)
```


### Target Identification and Made-Up Details

We delved into the 179 generations where GPT-3 successfully identify the sexist or racist text to see if the explanation provide an identification of who the target is and if the explanation is accompanied with made-up details. The results of target identification is displayed in Table X. 116 out of the 179 cases, the model provided an explanation along with the identification of the target (women, immigrants... etc). In some cases, the model generated explanations along with made-up details such as assigning false source to the given text. The number of cases where made-up details are found is shown in Table X. Nearly one third of the times, the model generated made-up details in the explanations. 

```{r openendedResultsTargetID}
open_ended_results_targetID <- open_ended_results_raw %>%
  filter(binary_match == 1) %>%
  group_by(identify_target) %>%
  mutate(count = n()) %>% 
  slice(1) %>% 
  select(identify_target, count)

open_ended_results_targetID <- open_ended_results_targetID %>% 
  mutate("Target Identified" = ifelse(identify_target == 1, "Yes", "No"))
open_ended_results_targetID <- open_ended_results_targetID[ , c("Target Identified", "count")]
colnames(open_ended_results_targetID) <- c("Target Identified", "Count")
open_ended_results_targetID %>% 
  knitr::kable(caption = "Open-ended result target identification counts",
               booktabs = TRUE)
```

```{r openendedResultsMadeupDetails}
open_ended_results_madeup_details <- open_ended_results_raw %>%
  filter(binary_match == 1) %>%
  group_by(madeup_details) %>%
  mutate(count = n()) %>% 
  slice(1) %>% 
  select(madeup_details, count)

open_ended_results_madeup_details %>% 
  knitr::kable(caption = "Open-ended result made-up details counts",
               booktabs = TRUE)
```

## Structured Responses

```{r}
structured_a8_t0_n30 <- read.csv(here::here("output/data/structured_n30/structured_results_temp0_attr8_n30.csv"))
structured_a8_t25_n30 <- read.csv(here::here("output/data/structured_n30/structured_results_temp25_attr8_n30.csv"))
structured_a8_t50_n30 <- read.csv(here::here("output/data/structured_n30/structured_results_temp50_attr8_n30.csv"))
structured_a8_t75_n30 <- read.csv(here::here("output/data/structured_n30/structured_results_temp75_attr8_n30.csv"))
structured_a8_t100_n30 <- read.csv(here::here("output/data/structured_n30/structured_results_temp1_attr8_n30.csv"))
structured_a6_t0_n30 <- read.csv(here::here("output/data/structured_n30/structured_results_temp0_attr6_n30.csv"))
structured_a6_t25_n30 <- read.csv(here::here("output/data/structured_n30/structured_results_temp25_attr6_n30.csv"))
structured_a6_t50_n30 <- read.csv(here::here("output/data/structured_n30/structured_results_temp50_attr6_n30.csv"))
structured_a6_t75_n30 <- read.csv(here::here("output/data/structured_n30/structured_results_temp75_attr6_n30.csv"))
structured_a6_t100_n30 <- read.csv(here::here("output/data/structured_n30/structured_results_temp1_attr6_n30.csv"))

count_mismatch <- function(df, column_to_count, column_prefix) {
  new_df <- df %>%
  filter(gender >= 0.75 | race >= 0.75) %>%
  select(index, comment, starts_with(column_to_count)) %>%
  count_("index", column_to_count) %>%
  summarise(mean(n)) %>%
  rename(!!column_prefix := "mean(n)" )
  new_df
}
```

```{r mismatchSummary}
### Target 
target_a8_t0 <- count_mismatch(structured_a8_t0_n30, "matched_target", "Temperature 0")
target_a8_t25 <- count_mismatch(structured_a8_t25_n30, "matched_target", "Temperature 25")
target_a8_t50 <- count_mismatch(structured_a8_t50_n30, "matched_target", "Temperature 50")
target_a8_t75 <- count_mismatch(structured_a8_t75_n30, "matched_target", "Temperature 75")
target_a8_t100 <- count_mismatch(structured_a8_t100_n30, "matched_target", "Temperature 100")
target_mismatch_summary <- add_column(Attribute = "Target", target_a8_t0,target_a8_t25,target_a8_t50,target_a8_t75,target_a8_t100)
target_mismatch_summary <- target_mismatch_summary[ , c("Attribute", "Temperature 0", "Temperature 25", "Temperature 50", "Temperature 75", "Temperature 100")]  
colnames(target_mismatch_summary) <- c("Attribute", "Temperature 0", "Temperature 0.25", "Temperature 0.5", "Temperature 0.75", "Temperature 1")

### Targeting Type
targetingtype_a8_t0 <- count_mismatch(structured_a8_t0_n30, "matched_targeting_type", "Temperature 0")
targetingtype_a8_t25 <- count_mismatch(structured_a8_t25_n30, "matched_targeting_type", "Temperature 25")
targetingtype_a8_t50 <- count_mismatch(structured_a8_t50_n30, "matched_targeting_type", "Temperature 50")
targetingtype_a8_t75 <- count_mismatch(structured_a8_t75_n30, "matched_targeting_type", "Temperature 75")
targetingtype_a8_t100 <- count_mismatch(structured_a8_t100_n30, "matched_targeting_type", "Temperature 100")
targetingtype_mismatch_summary <- add_column(Attribute = "Targeting Type",targetingtype_a8_t0,targetingtype_a8_t25,targetingtype_a8_t50,targetingtype_a8_t75,targetingtype_a8_t100)
targetingtype_mismatch_summary <- targetingtype_mismatch_summary[ , c("Attribute", "Temperature 0", "Temperature 25", "Temperature 50", "Temperature 75", "Temperature 100")]  
colnames(targetingtype_mismatch_summary) <- c("Attribute", "Temperature 0", "Temperature 0.25", "Temperature 0.5", "Temperature 0.75", "Temperature 1")

### Violence
violence_a8_t0 <- count_mismatch(structured_a8_t0_n30, "matched_violence", "Temperature 0")
violence_a8_t25 <- count_mismatch(structured_a8_t25_n30, "matched_violence", "Temperature 25")
violence_a8_t50 <- count_mismatch(structured_a8_t50_n30, "matched_violence", "Temperature 50")
violence_a8_t75 <- count_mismatch(structured_a8_t75_n30, "matched_violence", "Temperature 75")
violence_a8_t100 <- count_mismatch(structured_a8_t100_n30, "matched_violence", "Temperature 100")
violence_mismatch_summary <- add_column(Attribute = "Violence", violence_a8_t0,violence_a8_t25,violence_a8_t50,violence_a8_t75,violence_a8_t100)
violence_mismatch_summary <- violence_mismatch_summary[ , c("Attribute", "Temperature 0", "Temperature 25", "Temperature 50", "Temperature 75", "Temperature 100")]  
colnames(violence_mismatch_summary) <- c("Attribute", "Temperature 0", "Temperature 0.25", "Temperature 0.5", "Temperature 0.75", "Temperature 1")

### Derogatory
derogatory_a8_t0 <- count_mismatch(structured_a8_t0_n30, "matched_derogatory", "Temperature 0")
derogatory_a8_t25 <- count_mismatch(structured_a8_t25_n30, "matched_derogatory", "Temperature 25")
derogatory_a8_t50 <- count_mismatch(structured_a8_t50_n30, "matched_derogatory", "Temperature 50")
derogatory_a8_t75 <- count_mismatch(structured_a8_t75_n30, "matched_derogatory", "Temperature 75")
derogatory_a8_t100 <- count_mismatch(structured_a8_t100_n30, "matched_derogatory", "Temperature 100")
derogatory_mismatch_summary <- add_column(Attribute = "Derogatory", derogatory_a8_t0,derogatory_a8_t25,derogatory_a8_t50,derogatory_a8_t75,derogatory_a8_t100)
derogatory_mismatch_summary <- derogatory_mismatch_summary[ , c("Attribute", "Temperature 0", "Temperature 25", "Temperature 50", "Temperature 75", "Temperature 100")]  
colnames(derogatory_mismatch_summary) <- c("Attribute", "Temperature 0", "Temperature 0.25", "Temperature 0.5", "Temperature 0.75", "Temperature 1")

### Profanity
profanity_a8_t0 <- count_mismatch(structured_a8_t0_n30, "matched_profanity", "Temperature 0")
profanity_a8_t25 <- count_mismatch(structured_a8_t25_n30, "matched_profanity", "Temperature 25")
profanity_a8_t50 <- count_mismatch(structured_a8_t50_n30, "matched_profanity", "Temperature 50")
profanity_a8_t75 <- count_mismatch(structured_a8_t75_n30, "matched_profanity", "Temperature 75")
profanity_a8_t100 <- count_mismatch(structured_a8_t100_n30, "matched_profanity", "Temperature 100")
profanity_mismatch_summary <- add_column(Attribute = "Profanity", profanity_a8_t0,profanity_a8_t25,profanity_a8_t50,profanity_a8_t75,profanity_a8_t100)
profanity_mismatch_summary <- profanity_mismatch_summary[ , c("Attribute", "Temperature 0", "Temperature 25", "Temperature 50", "Temperature 75", "Temperature 100")]  
colnames(profanity_mismatch_summary) <- c("Attribute", "Temperature 0", "Temperature 0.25", "Temperature 0.5", "Temperature 0.75", "Temperature 1")

### Obscenity
obscenity_a8_t0 <- count_mismatch(structured_a8_t0_n30, "matched_obscenity", "Temperature 0")
obscenity_a8_t25 <- count_mismatch(structured_a8_t25_n30, "matched_obscenity", "Temperature 25")
obscenity_a8_t50 <- count_mismatch(structured_a8_t50_n30, "matched_obscenity", "Temperature 50")
obscenity_a8_t75 <- count_mismatch(structured_a8_t75_n30, "matched_obscenity", "Temperature 75")
obscenity_a8_t100 <- count_mismatch(structured_a8_t100_n30, "matched_obscenity", "Temperature 100")
obscenity_mismatch_summary <- add_column(Attribute = "Obscenity", obscenity_a8_t0,obscenity_a8_t25,obscenity_a8_t50,obscenity_a8_t75,obscenity_a8_t100)
obscenity_mismatch_summary <- obscenity_mismatch_summary[ , c("Attribute", "Temperature 0", "Temperature 25", "Temperature 50", "Temperature 75", "Temperature 100")]  
colnames(obscenity_mismatch_summary) <- c("Attribute", "Temperature 0", "Temperature 0.25", "Temperature 0.5", "Temperature 0.75", "Temperature 1")

### Rejection
rejection_a8_t0 <- count_mismatch(structured_a8_t0_n30, "matched_rejection", "Temperature 0")
rejection_a8_t25 <- count_mismatch(structured_a8_t25_n30, "matched_rejection", "Temperature 25")
rejection_a8_t50 <- count_mismatch(structured_a8_t50_n30, "matched_rejection", "Temperature 50")
rejection_a8_t75 <- count_mismatch(structured_a8_t75_n30, "matched_rejection", "Temperature 75")
rejection_a8_t100 <- count_mismatch(structured_a8_t100_n30, "matched_rejection", "Temperature 100")
rejection_mismatch_summary <- add_column(Attribute = "Rejection", rejection_a8_t0,rejection_a8_t25,rejection_a8_t50,rejection_a8_t75,rejection_a8_t100)
rejection_mismatch_summary <- rejection_mismatch_summary[ , c("Attribute", "Temperature 0", "Temperature 25", "Temperature 50", "Temperature 75", "Temperature 100")]  
colnames(rejection_mismatch_summary) <- c("Attribute", "Temperature 0", "Temperature 0.25", "Temperature 0.5", "Temperature 0.75", "Temperature 1")

### Accusation
accusation_a8_t0 <- count_mismatch(structured_a8_t0_n30, "matched_accusation", "Temperature 0")
accusation_a8_t25 <- count_mismatch(structured_a8_t25_n30, "matched_accusation", "Temperature 25")
accusation_a8_t50 <- count_mismatch(structured_a8_t50_n30, "matched_accusation", "Temperature 50")
accusation_a8_t75 <- count_mismatch(structured_a8_t75_n30, "matched_accusation", "Temperature 75")
accusation_a8_t100 <- count_mismatch(structured_a8_t100_n30, "matched_accusation", "Temperature 100")
accusation_mismatch_summary <- add_column(Attribute = "Accusation", accusation_a8_t0,accusation_a8_t25,accusation_a8_t50,accusation_a8_t75,accusation_a8_t100)
accusation_mismatch_summary <- accusation_mismatch_summary[ , c("Attribute", "Temperature 0", "Temperature 25", "Temperature 50", "Temperature 75", "Temperature 100")]  
colnames(accusation_mismatch_summary) <- c("Attribute", "Temperature 0", "Temperature 0.25", "Temperature 0.5", "Temperature 0.75", "Temperature 1")
```

```{r mismatchSummaryTable, include=FALSE}
all_attr_summary <- add_row(target_mismatch_summary,targetingtype_mismatch_summary) %>%
  add_row(violence_mismatch_summary) %>%
  add_row(derogatory_mismatch_summary)%>%
  add_row(profanity_mismatch_summary)%>%
  add_row(obscenity_mismatch_summary)%>%
  add_row(rejection_mismatch_summary)%>%
  add_row(accusation_mismatch_summary)
colnames(all_attr_summary) <- c("Attribute", "Temp 0", "Temp 0.25", "Temp 0.5", "Temp 0.75", "Temp 1")
all_attr_summary %>% 
  knitr::kable(caption = "Structured result average number of attribute matches in temperature 0, 0.25, 0.5, 0.75 and 1",
               booktabs = TRUE)
```

```{r}
merge_df_30n <- function(df, temp) {
  new_df <- df %>%
  filter(gender >= 0.75 | race >= 0.75) %>%
  group_by(index) %>%
  summarise_if(is.numeric, sum, na.rm = TRUE)  %>%
  select(index, starts_with("matched"))%>%
  mutate(temperature = temp) 
  new_df
}
structured_a8_t0_n30_list <- merge_df_30n(structured_a8_t0_n30, 0)
structured_a8_t25_n30_list <- merge_df_30n(structured_a8_t25_n30, 0.25)
structured_a8_t50_n30_list <- merge_df_30n(structured_a8_t50_n30, 0.5)
structured_a8_t75_n30_list <- merge_df_30n(structured_a8_t75_n30, 0.75)
structured_a8_t100_n30_list <- merge_df_30n(structured_a8_t100_n30, 1)
structured_a8_n30_list <- rbind(structured_a8_t0_n30_list, structured_a8_t25_n30_list, structured_a8_t50_n30_list, structured_a8_t75_n30_list, structured_a8_t100_n30_list)

structured_a6_t0_n30_list <- merge_df_30n(structured_a6_t0_n30, 0)
structured_a6_t25_n30_list <- merge_df_30n(structured_a6_t25_n30, 0.25)
structured_a6_t50_n30_list <- merge_df_30n(structured_a6_t50_n30, 0.5)
structured_a6_t75_n30_list <- merge_df_30n(structured_a6_t75_n30, 0.75)
structured_a6_t100_n30_list <- merge_df_30n(structured_a6_t100_n30, 1)
structured_a6_n30_list <- rbind(structured_a6_t0_n30_list, structured_a6_t25_n30_list, structured_a6_t50_n30_list, structured_a6_t75_n30_list, structured_a6_t100_n30_list)
```

### Number of Matched Numbers within Different Temperatures 

Figure X shows the structured result average number of attribute matches in temperature 0, 0.25, 0.5, 0.75 and 1. We observe a general trend of number of matches decreasing as the temperature increases. Except for 'Target', 'Profanity' and 'Obscenity' where the model performed the best under temperature 0.25 by a thin margin, the results of temperature 0 have the highest number of matches with human evaluation in every other attribute. Moreover, as the distribution of matched number varies within wider ranges as the temperature increases.  

```{r, fig.height=4}
p1 <- ggplot(structured_a8_n30_list, aes(factor(temperature), matched_target))
p1 <- p1 + geom_boxplot()

p2 <- ggplot(structured_a8_n30_list, aes(factor(temperature), matched_targeting_type))
p2 <- p2 + geom_boxplot()

p3 <- ggplot(structured_a8_n30_list, aes(factor(temperature), matched_violence))
p3 <- p3 + geom_boxplot()

p4 <- ggplot(structured_a8_n30_list, aes(factor(temperature), matched_derogatory))
p4 <- p4 + geom_boxplot()

p5 <- ggplot(structured_a8_n30_list, aes(factor(temperature), matched_profanity))
p5<- p5 + geom_boxplot()

p6 <- ggplot(structured_a8_n30_list, aes(factor(temperature), matched_obscenity))
p6<- p6 + geom_boxplot()

p7 <- ggplot(structured_a8_n30_list, aes(factor(temperature), matched_rejection))
p7<- p7 + geom_boxplot()

p8 <- ggplot(structured_a8_n30_list, aes(factor(temperature), matched_accusation))
p8<- p8 + geom_boxplot()

gridExtra::grid.arrange(p1,p2,p3,p4,p5,p6,p7,p8, ncol=2)
```

### Number of Matched Numbers within Granular Attributes V.S. General Attribute

We define ‘Insult’ as a general attribute that covers ‘Derogatory’, ‘Profanity’, and ‘Obscenity’, which are what we called granular attributes. We examine how GPT-3 performs in identifying a more general attribute compared to identifying more granular attributes. Figure X shows the average numbers of matches in ‘Insult’, ‘Derogatory’, ‘Profanity’, and ‘Obscenity’ in temperature 0, 0.25, 0.5, 0.75 and 1.

```{r insultMismatchSummaryLineChart}
insult_df <- add_column(structured_a6_n30_list["index"],structured_a6_n30_list["temperature"], structured_a6_n30_list["matched_insult"], structured_a8_n30_list["matched_derogatory"], structured_a8_n30_list["matched_profanity"],  structured_a8_n30_list["matched_obscenity"])
insult_df <- insult_df %>%
  group_by(index, temperature) %>%
  summarise_if(is.numeric, sum, na.rm = TRUE) %>%
  group_by(temperature) %>%
  select(-index)%>%
  summarise_if(is.numeric, mean, na.rm = TRUE) %>%
  pivot_longer(!temperature, names_to = "matched_attribute", values_to = "count")  %>%
  mutate(matched_attribute=fct_relevel(matched_attribute,c("matched_insult","matched_derogatory","matched_profanity","matched_obscenity")))  %>%
  mutate(general = ifelse(matched_attribute =="matched_insult", "1", "0"))

values = c( c(matched_insult="red"), "#a0b9e3", "#4c82df", "#0c089c")

ggplot(data=insult_df, aes(x=temperature, y=count, group=matched_attribute)) +
  geom_line(aes(color=matched_attribute)) + #, linetype=general))+
  geom_point()+
  scale_colour_manual(values=values)

```

# Discussion

## Variety of open-ended explanation

**Example below**
Because GPT-3’s responses can be very different each time, we prompt GPT-3 five times for each example to help us examine the variety of the responses and also increase the chance of getting a reasonable response. Output 1 “it is a generalization about women’s sports, saying that they are a joke. Generalizations are usually untrue and therefore the text is sexist”. This output mentions “generalization”, which is what the statement is but not so adequate, if you said “men are taller than women”, that’s a generalization as well but you wouldn’t think that’s a sexist comment. In output 2 is a straight no, explaining why you say women sport is a joke doesn’t make it not sexist. Output 3 on the other hand is spot on, it focus on the word “joke”, and explain that joke has a connotation of something that is not serious. Output 4 did a good job as well, like output 3 it also points out the implication of women sports are less than men sports. Output 5, the first part is okay as it mentioned discrimination, but the latter part just seems like a glitch. 

Open-ended explanations can be diverse and hard to control.


## Structured: beyond sexisma and racism

This approach actually permits the model to detect problematic texts beyond the scope of sexism and racism, because now, the targets can be of any groups identified based on not only gender and race, but also religion, sexual orientation, and disability. 

## Not Explainable AI

Explainable AI is an approach that’s been very popular to tackle the black box problem in AI decision making. Often times, we have hard time to understand why AI makes the decision it makes, and there’s no way to deconstruct it. Explainable AI is the approach of that decision making process auditable and transparent. Why we do is not explainable AI because the explanations on why a text passage is sexist or racist provided by GPT-3 are from a social lense, and are not shedding a light on any technical or system process for the output. In other words, the explanations displayed are not the rationale GPT-3 made the decisions based on. GPT-3 is saying that the text is sexist or racist because of the math behind the model, not because of the explanations it generated. 


# References
